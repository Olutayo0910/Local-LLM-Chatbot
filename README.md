# Chatbot Application with Flask and Langchain Ollama

This is a simple chatbot application built with Flask and integrated with the Langchain Ollama library. The application uses a language model to generate answers based on the conversation history and user questions.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [License](#license)

## Features

- Interactive chatbot interface
- Utilizes Langchain Ollama for generating responses
- Maintains conversation context for more coherent answers

## Installation

To set up the project locally, follow these steps:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/yourrepository.git
   cd yourrepository

2. **Create a virtual environment**:
    ```bash
    python3 -m venv chatbot
    source chatbot/bin/activate

3. **Install dependencies**:
    ```bash
    pip install -r requirements.txt


## Usage

1. **Navigate to the application directory:**
    ```bash
    cd Local-LLM-Chatbot

2. **Activate the virtual environment:**
    ```bash
    source chatbot/bin/activate

3. **Run the application**
    ```bash
    python3 main.py

Open your web browser and go to http://127.0.0.1:5000 to interact with the chatbot.

